{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f231e745-65ca-4b6c-a07a-410dcd7a1d88",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'PyPDF2'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9944\\2797840568.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mPyPDF2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPdfReader\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBertTokenizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTFBertForQuestionAnswering\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'PyPDF2'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PyPDF2 import PdfReader\n",
    "import re\n",
    "import tensorflow as tf\n",
    "from transformers import BertTokenizer, TFBertForQuestionAnswering\n",
    "import numpy as np\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "575ddf56-a4a0-4218-9933-4b2b20643f3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: PyPDF2 in c:\\users\\saisr\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (3.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8430ce70-48f3-46aa-88bd-ed1800cafe0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    text = \"\"\n",
    "    with open(pdf_path, 'rb') as file:\n",
    "        pdf_reader = PdfReader(file)\n",
    "        for page in pdf_reader.pages:\n",
    "            text += page.extract_text()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52037568-a957-4790-b07c-c872b58d1351",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def preprocess_text(text):\n",
    "  \n",
    "    text = re.sub(r'\\n+', ' ', text) \n",
    "    text = re.sub(r'\\s+', ' ', text)  \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28dd9d04-480f-4d7c-ae7d-8fdb4b78ad39",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'BertTokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9944\\186752260.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Load the pre-trained BERT model and tokenizer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtokenizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBertTokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'bert-base-uncased'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTFBertForQuestionAnswering\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'bert-base-uncased'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'BertTokenizer' is not defined"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = TFBertForQuestionAnswering.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fe951e96-690b-411d-a2ca-534bd2248515",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to preprocess the dataset\n",
    "def preprocess_data(pdf_directory):\n",
    "    dataset = []\n",
    "    for filename in os.listdir(pdf_directory):\n",
    "        if filename.endswith('.pdf'):\n",
    "            pdf_path = os.path.join(pdf_directory, filename)\n",
    "            text = extract_text_from_pdf(pdf_path)\n",
    "            text = preprocess_text(text)\n",
    "            dataset.append(text)\n",
    "            print(len(text))\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "01c777b0-8992-4775-9aab-bcd719b87db1",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'datasets'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9944\\2950062385.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Preprocess the dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mpdf_directory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'datasets'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreprocess_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpdf_directory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9944\\2736139147.py\u001b[0m in \u001b[0;36mpreprocess_data\u001b[1;34m(pdf_directory)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mpreprocess_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpdf_directory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpdf_directory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'.pdf'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m             \u001b[0mpdf_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpdf_directory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'datasets'"
     ]
    }
   ],
   "source": [
    "# Preprocess the dataset\n",
    "pdf_directory = 'datasets'\n",
    "dataset = preprocess_data(pdf_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ca5443cd-a8db-4685-a3af-c8f896e86b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_input(input_text):\n",
    "  \n",
    "    return input_text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d5867030-a7e9-4db2-a846-4d86554a8302",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=3e-5)\n",
    "model.compile(optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "97a4e09e-8776-43ff-a140-3a7ba5247951",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_large_context(context, question):\n",
    "    answers = []\n",
    "    start_logits_list = []\n",
    "    end_logits_list = []\n",
    "    window_size = 512 \n",
    "    stride = 256  \n",
    "    for i in range(0, len(context), stride):\n",
    "        window = context[i:i + window_size]\n",
    "        predicted_answer, start_logits, end_logits = predict_answer(window, question)  # Pass tokenized context to predict_answer\n",
    "        answers.append(predicted_answer)\n",
    "        start_logits_list.append(start_logits)\n",
    "        end_logits_list.append(end_logits)\n",
    "    return answers, start_logits_list, end_logits_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "75ae990c-062a-46bb-8e0e-190cd79d4389",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_answer_for_large_context(context, question):\n",
    "    context = preprocess_text(context)\n",
    "    answers, start_logits_list, end_logits_list = process_large_context(context, question)\n",
    "    answers_list = []\n",
    "    start_probs_list = []\n",
    "    end_probs_list = []\n",
    "\n",
    "  \n",
    "    for i in range(len(answers)):\n",
    "        if(answers[i].strip() != \"\"):\n",
    "            answers_list.append(answers[i])\n",
    "            start_probs_list.append(start_logits_list[i])\n",
    "            end_probs_list.append(end_logits_list[i])\n",
    "    answers = answers_list\n",
    "\n",
    "    # Calculate confidence scores for each answer\n",
    "    confidence_scores = []\n",
    "    for start_probs, end_probs in zip(start_probs_list, end_probs_list):\n",
    "        confidence_score = np.sum(start_probs) * np.sum(end_probs)\n",
    "        confidence_scores.append(confidence_score)\n",
    "\n",
    "    # Select the answer with the highest confidence score\n",
    "    best_answer_index = np.argmax(confidence_scores)\n",
    "    best_answer = answers[best_answer_index]\n",
    "    best_confidence_score = confidence_scores[best_answer_index]\n",
    "\n",
    "    return best_answer, best_confidence_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "dbc0767f-7d66-4484-aa09-512b4e041e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predict_answer(context, question):\n",
    "  \n",
    "    tokenized_input = tokenizer(context, question, padding='max_length', truncation='only_first', max_length=512, return_tensors=\"tf\")\n",
    "    model_trained = model(tokenized_input)\n",
    "\n",
    "    start_logits = model_trained[0]\n",
    "    end_logits = model_trained[1]\n",
    "    \n",
    "    start_logits = start_logits[0]\n",
    "    end_logits = end_logits[0]\n",
    "\n",
    "    start_logits = np.array(start_logits).astype(np.float32)\n",
    "    end_logits = np.array(end_logits).astype(np.float32)\n",
    "    \n",
    "    start_index = np.argmax(start_logits)\n",
    "    end_index = np.argmax(end_logits)\n",
    "    \n",
    " \n",
    "    answer_tokens = tokenized_input[\"input_ids\"][0][start_index:end_index+1].numpy()\n",
    "    \n",
    "    # Decode the answer tokens into text using the tokenizer\n",
    "    answer = tokenizer.decode(answer_tokens)\n",
    "    \n",
    "    # Return the decoded answer\n",
    "    return answer, start_logits, end_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "077ea146-668f-4d5c-a9da-7005ddef8ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to start the chatbot\n",
    "def chatbot():\n",
    "    print(\"Chatbot: Hi! I'm here to answer your questions.\")\n",
    "    print(\"Chatbot: Type 'exit' to end the conversation.\")\n",
    "    while True:\n",
    "        user_input = input(\"You: \")\n",
    "        user_input = preprocess_input(user_input)\n",
    "        \n",
    "        if user_input == 'exit':\n",
    "            print(\"Chatbot: Goodbye!\")\n",
    "            break\n",
    "        \n",
    "        context = dataset[1]\n",
    "        # print(context)\n",
    "        predicted_answer, confidence = predict_answer_for_large_context(context, user_input)\n",
    "        print(confidence)\n",
    "        print(\"Chatbot:\", predicted_answer)\n",
    "        break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "dffebb40-2747-4b47-ac8b-33fab3e43340",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: Hi! I'm here to answer your questions.\n",
      "Chatbot: Type 'exit' to end the conversation.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  what are solutions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6778.5913\n",
      "Chatbot: a will be xa = a a b n n n ( 1. 5 ) for a solution containing i number of components, we have : xi = i 1 2 i....... n n n n = i in n ( 1. 6 ) it can be shown that in a given solution sum of all the mole fractions is unity, i. e. x1 + x2 +.................. + xi = 1 ( 1. 7 ) mole fraction unit is very useful in relating some physical properties of solutions, say vapour pressure with the concentration of the\n"
     ]
    }
   ],
   "source": [
    "\n",
    "chatbot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb8d202-2ee0-4913-82e1-db0380ab3b41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
